[
  {
    "objectID": "index.html#inicio",
    "href": "index.html#inicio",
    "title": "INVESTIGACIÓN SOBRE MÉTODOS DE PREDICCIÓN EN SERIES DE TIEMPO JERÁRQUICAS O AGRUPADAS",
    "section": "Inicio",
    "text": "Inicio\n\nGithub\nLa documentación y desarrollo de este proyecto se localiza en el siguiente repositorio: proj-met-causalinfer\n\n\nReferencias\n\nHyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on April 30, 2023.\n\nCapítulo 11\n\nLos datos utilizados se obtuvieron de:\n\nKaggle - Tabular Playground Series - Sep 2022 - Train\nKaggle - Tabular Playground Series - Sep 2022 - Test"
  },
  {
    "objectID": "01-proyecto.html#introducción",
    "href": "01-proyecto.html#introducción",
    "title": "1  Introducción y Definición del Problema",
    "section": "1.1 Introducción",
    "text": "1.1 Introducción\nUn aspecto relevante para los tomadores de decisión es el hecho de poder tener información confiable y consistente, de tal forma que las proyecciones o valores resultantes sean razonables. Cuando se realizan proyecciones en series de tiempo, nos enfrentamos a un cojunto de elementos que debemos atacar de forma secuencial y sencillla para poder derterminar los patrones naturales que emergen de la serie, tales como tendencia, ciclicidad y estacionalidad en diversas fases. En adición, cuando observamos datos desagregados por diversas categorías anidados dentro de categorías o incluso por agrupación de categorías, nos enfrentamos a series de tiempo Jerárquicas o Jerárquicas Agrupadas.\nHemos seleccionado una base de datos simple de las librerías de Kaggle (datos artificiales) que usaremos para poder ejemplificar los temas a desarrollar."
  },
  {
    "objectID": "01-proyecto.html#objetivo",
    "href": "01-proyecto.html#objetivo",
    "title": "1  Introducción y Definición del Problema",
    "section": "1.2 Objetivo",
    "text": "1.2 Objetivo\n\nRealizar una investigación general sobre los métodos actuales disponibles para resolver el problema que surge en las proyecciones de series de tiempo con datos desagregados por diversos atributos de interés, ya que buscamos consistencia y coherencia en las estimaciones tanto agregadas como desagregadas.\nImplementar un caso de estudio sencillo utilizando un dataset de la librería de Kaggle que nos permita implementar las técnicas investigadas."
  },
  {
    "objectID": "01-proyecto.html#planteamiento-del-problema",
    "href": "01-proyecto.html#planteamiento-del-problema",
    "title": "1  Introducción y Definición del Problema",
    "section": "1.3 Planteamiento del problema",
    "text": "1.3 Planteamiento del problema\nPara utilizar las técnicas discutidas en esta sección se planterá el problema de pronosticar las ventas de una empresa a lo largo de los años 2017 a 2020 con una estructura jerárquica en los datos. El conjunto de datos original cuenta con observaciones a nivel diario, sin embargo, con el fin de simplificar el problema y ejemplificar la solución de este tipo de estructuras de series temporales se optó por presentar la serie a nivel mensual.\nDATABASE CLI: kaggle competitions download -c tabular-playground-series-sep-2022 Tabular Playground Series - Sep 2022\nLos datos son ficiticios y fueron creados como dataset lúdico para incrementar las habilidades en los modelos de Aprendizaje de Máquina. No obstante, la estructura de diseño permite explotarlo aún más, en nuestro caso, para ejemplificar prediccines en modelos jerárquicos o agrupados. Es importante mencionar que se integraron efectos naturales de las series de tiempo como son días feriados, estacionalidad, tendencia, etc.\nBásicamente, consiste en la predicción del valor de las ventas durante el año 2021 para 2 tiendas que compiten entre sí y que están localizadas en 6 distintos países de Europa actualmente.\nUtilizaremos un diagrama de árbol para analizar la estructura de los datos, que consiste en series de tiempo con 3 niveles jerárquicos:\n\n6 países: Belgium, France, Germany, Italy, Poland, Spain.\n2 tipos de tienda: KaggleMart, KaggleRama.\n4 productos: Kaggle Advanced Techniques, Kaggle for Kids: One Smart Goose, Kaggle Getting Started, Kaggle Recipe Book.\n\n\nEn el siguiente resumen podemos observar las características principales de nuestra información. Al ser un base de datos artificial, no encontramos problemas como desbalanceo o valores faltantes. Como se mencionó anteriormente, tenemos 6 países, 2 categorías para tienda y 4 tipos de producto distintos.\n\n\n\nComo es usual, la siguiente tabla nos muestra las primeras observaciones de nuestros datos para poder tener una inspección rápida:\n\nsales <- read_delim(\"../datos/sales.csv\")\nsales_m <- sales |>\n    mutate(t = (year(date)-year(min(date)))*12 + (month(date)-month(min(date)))) |>\n    mutate(date = year(date)*100+month(date)) |>\n    group_by(date,t,country,store,product) |>\n    summarise(num_sold = sum(num_sold,na.rm = TRUE)) \n\nhead(sales_m) |> kable()\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nt\ncountry\nstore\nproduct\nnum_sold\n\n\n\n\n201701\n0\nBelgium\nKaggleMart\nKaggle Advanced Techniques\n13345\n\n\n201701\n0\nBelgium\nKaggleMart\nKaggle for Kids: One Smart Goose\n13589\n\n\n201701\n0\nBelgium\nKaggleMart\nKaggle Getting Started\n9807\n\n\n201701\n0\nBelgium\nKaggleMart\nKaggle Recipe Book\n8429\n\n\n201701\n0\nBelgium\nKaggleRama\nKaggle Advanced Techniques\n4697\n\n\n201701\n0\nBelgium\nKaggleRama\nKaggle for Kids: One Smart Goose\n4722\n\n\n\n\n\nCon base en lo anterior, no se tiene que realizar pre-procesamiento alguno a nuestra información. Así mismo, nuestro objetivo es el poder realizar predicciones en series de tiempo jerárquicas en datos desagregados y no inferencia sobre las variables y sus relaciones, por lo que no será implementado un análisis EDA, si no que nos enfocaremos en conocer las cualidades de nuestra serie de tiempo para el tratamiento adecuado que debe considerarse en las componentes de una serie de tiempo (tendencia, ciclididad, estacionalidad, autocorrelación) previo a realizar las predicciones y aplicar las metodologías para lograr la consistencia al predecir en el modelo agregado."
  },
  {
    "objectID": "02-proyecto.html#series-de-tiempo-jerárquicas",
    "href": "02-proyecto.html#series-de-tiempo-jerárquicas",
    "title": "2  Tipos de estructuras que surgen en datos desagregados",
    "section": "2.1 Series de Tiempo Jerárquicas",
    "text": "2.1 Series de Tiempo Jerárquicas\nEsencialmente, estas series se organizan en una estructura por niveles, siendo el nivel 0 la jerarquía más alta, es decir, el nivel de mayor agregación de los datos.\nLa siguiente figura nos permitira conceptualizar de forma intuitiva las estructuras jerárquicas y servirá como base para construir las ecuaciones y notación necesaria.\n Figura A: diagrama para series de tiempo jerárquicas\n\n\n\nDenotemos la \\(t\\)th observación por \\(y_{t}\\) donde \\(t=1,...,T\\). En el gráfico anterior podemos osbervar que la estructura jerárquica nos muestra que el Total está desagregado en 2 series \\(A\\) y \\(B\\) en el nivel 1, que a su vez se desagregan en 3 y 2 series respectivamente en el nivel más bajo. Esto implica que tenemos 8 (1, 2, 5) series, con 5 en el último nivel de la jerarquía.\nPara cualquier tiempo \\(t\\), las observaciones en el último nivel inferior de la jerarquía deben sumar con las observaciones de las series superiores. Por tanto, podemos construir ecuaciones de agregación restricta (por llamarles de alguna forma):\n\\[\n\\begin{align}\n\\tag{2.1.1}\ny_{t}=y_{\\text{AA},t}+y_{\\text{AB},t}+y_{\\text{AC},t}+y_{\\text{BA},t}+y_{\\text{BB},t}\n\\end{align}\n\\]\nequivalente a:\n\\[\n\\begin{align}\n\\tag{2.1.2}\ny_{t}=y_{\\text{A},t}+y_{\\text{B},t}\n\\end{align}\n\\]\ncon\n\\[\n\\begin{align}\n\\tag{2.1.3}\ny_{\\text{A},t}=y_{\\text{AA},t}+y_{\\text{AB},t}+y_{\\text{AC},t} \\quad \\text{y} \\quad\ny_{\\text{B},t}=+y_{\\text{BA},t}+y_{\\text{BB},t}\n\\end{align}\n\\]\nPor practicidad, es recomendable que utilicemos una notación matricial (por ser más compacta). Básicamente, buscamos una matriz que induzca la forma en que las series inferiores deben agregarse. Para ello, contruimos una matriz de acumulación \\(S\\) de orden \\(n \\times m\\) de la siguiente forma (con base a la estructura de nuestro ejemplo):\n\\[\n\\begin{bmatrix}\n    y_{t} \\\\\n    y_{\\text{A},t} \\\\\n    y_{\\text{B},t} \\\\\n    y_{\\text{AA},t} \\\\\n    y_{\\text{AB},t} \\\\\n    y_{\\text{AC},t} \\\\\n    y_{\\text{BA},t} \\\\\n    y_{\\text{BB},t}\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix}\n    1 & 1 & 1 & 1 & 1 \\\\\n    1 & 1 & 1 & 0 & 0 \\\\\n    0 & 0 & 0 & 1 & 1 \\\\\n    1  & 0  & 0  & 0  & 0  \\\\\n    0  & 1  & 0  & 0  & 0  \\\\\n    0  & 0  & 1  & 0  & 0  \\\\\n    0  & 0  & 0  & 1  & 0  \\\\\n    0  & 0  & 0  & 0  & 1\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    y_{\\text{AA},t} \\\\\n    y_{\\text{AB},t} \\\\\n    y_{\\text{AC},t} \\\\\n    y_{\\text{BA},t} \\\\\n    y_{\\text{BB},t}\n  \\end{bmatrix}\n\\]\ncuya ecuación queda definida por:\n\\[\n\\begin{align}\n\\tag{2.1.4}\n\\boldsymbol{y}_t=\\boldsymbol{S}\\boldsymbol{b}_{t},\n\\end{align}\n\\]\ndonde:\n\n\\(\\boldsymbol{y}_t\\): vector \\(n\\)-dimensional con todas las observaciones de la jerarquía en el tiempo \\(t\\).\n\n\\(\\boldsymbol{S}\\): matriz de acumulación.\n\n\\(\\boldsymbol{b}_t\\): es un vector \\(m\\)-dimensional de las observaciones en el nivel último inferior de la jerarquía.\n\n¿Qué representa nuestra matriz, cómo induce las relaciones de jerarquía, cómo se construye?.\n\nLa primer fila de la matriz representa la ecuación (2.1.1), la serie en el nivel más alto de la jerarquía.\nEn este caso, la segunda y tercer fila representan (2.1.3) correspondientes a las series \\(A\\) y \\(B\\) para el nivel 2 de nuestro ejemplo.\n\\(\\vdots\\) (similar al nivel 2, se construyen niveles adicionales inferiores hasta llegar al penúltimo nivel).\n\n\nEl último nivel deberá ser presentado por una matriz identidad \\(I_m\\).\n\nEjemplo. Kaggle Tabular Playground Series - Sep 2022\nComo mencionamos en la sección 1, los datos corresponden a 6 países que a su vez poseen 2 tiendas (que compiten) y las cuales comercializan 4 productos de interés para los accionistas. El área de desarrollo comercial y presupuesto está interesada en conocer el valor de las ventas totales para 2021 en la región Europea; así mismo, desean conocer los ventas por producto, por tienda y por país para determinar el nivel de producción requerido por país garantizando que no exista desabasto ni sobreinventario (esto se analizará en series de tiempo agrupadas); finalmente, es requerido analizar la rentabilidad que se espera por tienda.\nComo bien sabemos, la paquetería fpp3 adapta los principios tidy al procesamiento de datos. Por lo que, lo primero que haremos es transfomar nuestro dataset a un tabla de datos para serie de tiempo denominada tsibble (time series tibble).\n\nsales_m <- sales |>\n    mutate(t = (year(date)-year(min(date)))*12 + (month(date)-month(min(date)))) |>\n    mutate(date = yearmonth(date)) |>\n    group_by(date,t,country,store,product) |>\n    summarise(num_sold = sum(num_sold,na.rm = TRUE)) |>\n    ungroup() |>\n    as_tsibble(index = date,key = c(country,store,product))\n\n`summarise()` has grouped output by 'date', 't', 'country', 'store'. You can\noverride using the `.groups` argument.\n\nhead(sales_m,2) |> kable()\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nt\ncountry\nstore\nproduct\nnum_sold\n\n\n\n\n2017 Jan\n0\nBelgium\nKaggleMart\nKaggle Advanced Techniques\n13345\n\n\n2017 Feb\n1\nBelgium\nKaggleMart\nKaggle Advanced Techniques\n12556\n\n\n\n\n\nLa función aggregate_key() se utiliza para crear series de tiempo jerárquicas; para especificar si corresponde a una estructura anidada utilizamos la notación parent/child. Esto genera filas adicionales a nuestro tsibble que corresponden a las observaciones de agregación generados para cada periodo.\nAnálisis de la tendencia\nAnalizaremos las tendencias de las ventas totales para todo Europa y desagregadas por país, luego por tienda y finalente por producto.\n\nsales_m |>\n  aggregate_key(country/store/product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(is_aggregated(store)) |>\n  autoplot(num_sold) +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales: Europa y por país\") +\n  facet_wrap(vars(country), scales = \"free_y\", ncol = 3) +\n  theme(legend.position = \"none\")\n\n\n\n\nObservamos un patrón cíclico de pico muy cercano al final del año que en particular en 2019 en algunos países se observó justo en el final del año (excepto en Belgium y Germany). Coincidentemente con la pandemia, se tuvo una caída abrupta en las ventas para todos los países durante el primer trimestre de 2020 y una tendencia de recuperación en el nivel de ventas posterior a este trimestre.\nEn terminos generales, se observa una tendencia decreciente durante el año con un repentino incremento hacia el final del mismo, por lo que será relevante observar el comportamiento de la estacionalidad.\nA gran escala, todos los países tuvieron un incremento considerable en las ventas en comparación con 2017, no obstante todos muestran una tendencia decreciente durante 2018 y 2019.\nOtro elemento adicional, es que podemos observar dos patrones muy bien definidos del comportamiento de las ventas que surgen en lo que podríamos considerar 2 regiones: 1. Región norte de Europa: France, Belgium y Germany. Una caída severa de sus niveles de ventas durante el primer trimestre de 2020 (niveles cercanos 0) con una recuperación durante los siguientes trimestres casi a niveles previos a la caída del primer trimestre. 2. Región sur de Europa: Poland, Italy y Spain. Un cambio abrupto en el nivel de ventas a partir de 2020, en particular Poland con un incremento del 250% y un incremento de aproximadamente un 40% para Italy y Spain. El impacto por la caída en en el primer trimestre fue moderado para los tres países.\nA nivel Nacional, observamos que el patrón de tendencia se rige en su mayoría por el comportamiento de la región sur, en particular en el fuete incremento que se experimentó en 2020.\n\nsales_m |>\n  aggregate_key(store/country/product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(is_aggregated(country)) |>\n  autoplot(num_sold) +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales: Europa y por tienda\") +\n  facet_wrap(vars(store), scales = \"free_y\", ncol = 3) +\n  theme(legend.position = \"none\")\n\n\n\n\nEl comporatmiento entre ambas tiendas es prácticamente el mismo pero a escalas diferentes, por lo que el agregado de Europa guarda este mismo patrón.\nComo era de esperarse, en comparación con lo observado por país, observamos los mismos elementos en las tres series: 1. Incremento significativo en el nivel de ventas para 2018 y 2019 en comparación con 2017; 2. Tendencia decreciente de 2018 a 2019; 3. Máximo histórico observado a finales de 2019 con una abrupta caída en el primer trimestre de 2020 y una tendencia de recuperación durante los siguientes trimestres para superar nuevamente el nivel de ventas histórico para el cierre del año 2020.\n\nsales_m |>\n  aggregate_key(product/store/country, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(is_aggregated(store)) |>\n  autoplot(num_sold) +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales: Europa y por producto\") +\n  facet_wrap(vars(product), scales = \"free_y\", ncol = 3) +\n  theme(legend.position = \"none\")\n\n\n\n\nFinalmente, cuando observamos la tendencia por producto observmos que en general tienen un comportamiento creciente y fuertemente estacional, excepto One Smart Goose que muestra un patron fluctuante (no estacionalidad visible), una tendencia creciente con una caída fuerte en 2019 y una recuperación en 2020.\nAnálisis de estacionalidad\nAnteriormente, ya observamo ciertos comportamientos estacionales en el análisis de tendencia, en particular nos interes la estacionalidad por producto y por país.\nEn el caso por producto, esperaríamos cierto comportamiento bien definido en la mayoría de los productos. En el análisis por país, de acuerdo a lo observado en la tendencia, consideramos que es factible obtener ciertos comportamientos bien definidos por la región norte y la región sur.\n\nsales_m |>\n  aggregate_key(country/store/product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(is_aggregated(store)) |>\n  select(-store) |>\n  mutate(country = factor(country)) |>\n  gg_season(num_sold) +\n  facet_wrap(vars(country), nrow = 4, scales = \"free_y\") +\n  labs(x = \"Mes\",y = \"Ventas (miles)\")\n\n\n\n\nDe forma consistente con el análisis de tendencia, los patrones de comportamiento estacional se encuentran bien definidos por las regiones mencionadas anteriormente, así como un dominio de la región norte con el agregado de todo Europa.\nAspectos que resaltan claramente con respecto al año 2020 y debemos tener presente son:\n\nEl comportamiento de la región norte en ausencia del 2020, tiene sus niveles de venta más altos tanto en los días alrededor del principio y fin de año así como durante el segundo trimestre (abril-junio). Visualmente podríamos establecer que sus valores promedio mensuales estarían en el rango entre 50 y 60.\nPara la región sur (Italy, Poland, Spain), también en asuencia de 2020 el patrón de comportamiento estacional es muy similar a la región norte pero con la diferencia de ser más bajo, con valores medios mernsuales entre 20 y 40.\nFinalmente, el 2020 muestra un cambio fuerte en los niveles de venta de la región sur, casi similar al observado en la región norte.\n\n\nsales_m |>\n  aggregate_key(product/store/country, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(is_aggregated(store)) |>\n  select(-store) |>\n  mutate(product = factor(product)) |>\n  gg_season(num_sold) +\n  facet_wrap(vars(product), nrow = 3, scales = \"free_y\")+\n  labs(x = \"Mes\",y = \"Ventas (miles)\")\n\n\n\n\nEl gráfico anterior muestra un comportamiento estacional perfectamente bien definido por cada producto, incluso 2020 en general mantiene este comportamiento pero incrementado en sus niveles de venta y con el claro impacto de caída durante el primer trimestre del 2020 y tendencia creciente durante los trimestres subsecuentes.\n\n\n\n\n\n\nNota\n\n\n\nEs necesario indicar que no se tiene información suficiente para poder determinar a qué obedece este crecimiento en los niveles de venta durante 2020; observamos que el crecimiento en las ventas puede obedecer a mayor ventas en los productos, pero esto también puede estar determinado por un crecimiento en tiendas en los países de las región sur que es donde se observó el creimiento."
  },
  {
    "objectID": "02-proyecto.html#series-de-tiempo-agrupadas",
    "href": "02-proyecto.html#series-de-tiempo-agrupadas",
    "title": "2  Tipos de estructuras que surgen en datos desagregados",
    "section": "2.2 Series de Tiempo Agrupadas",
    "text": "2.2 Series de Tiempo Agrupadas\nEn este caso, los datos no tienen una forma jerárquica de desagregarse naturalmente. La siguiente figura es un ejemplo simple para una estructura agrupada.\n Figura B: diagrama para series de tiempo agrupadas\n\n\n\nObservemos que en estas estructuras existen formas alternativas de agregación. En el ejemplo anterior, la agregación de \\(X\\) y \\(Y\\) es alternativa con \\(A\\) y \\(B\\).\nContinuando con el ejemplo del gráfico, tenemos entonces que para cualquier tiempo \\(t\\):\n\\[\n\\begin{align}\n  \\tag{2.2.1}\n  y_{t}=y_{\\text{AX},t}+y_{\\text{AY},t}+y_{\\text{BX},t}+y_{\\text{BY},t}\n\\end{align}\n\\]\nPara el primer nivel de la estructura agrupada:\n\\[\n\\begin{align}\n  \\tag{2.2.2}\n  y_{\\text{A},t}=y_{\\text{AX},t}+y_{\\text{AY},t}  \\quad \\quad\n  y_{\\text{B},t}=y_{\\text{BX},t}+y_{\\text{BY},t}\n\\end{align}\n\\]\nNo obstante, obervemos que alternativamente también se tiene:\n\\[\n\\begin{align}\n  \\tag{2.2.3}\n  y_{\\text{X},t}=y_{\\text{AX},t}+y_{\\text{BX},t}  \\quad \\quad\n  y_{\\text{Y},t}=y_{\\text{AY},t}+y_{\\text{BY},t}\n\\end{align}\n\\]\nDe forma análoga a la construcción de notación matricial en el caso jerárquico, construimos una matriz de acumulación \\(S\\) de orden \\(n \\times m\\):\n\\[\n\\begin{bmatrix}\n    y_{t} \\\\\n    y_{\\text{A},t} \\\\\n    y_{\\text{B},t} \\\\\n    y_{\\text{X},t} \\\\\n    y_{\\text{Y},t} \\\\\n    y_{\\text{AX},t} \\\\\n    y_{\\text{AY},t} \\\\\n    y_{\\text{BX},t} \\\\\n    y_{\\text{BY},t}\n  \\end{bmatrix}\n  =\n  \\begin{bmatrix}\n    1 & 1 & 1 & 1 \\\\\n    1 & 1 & 0 & 0 \\\\\n    0 & 0 & 1 & 1 \\\\\n    1 & 0 & 1 & 0 \\\\\n    0 & 1 & 0 & 1 \\\\\n    1  & 0  & 0  & 0  \\\\\n    0  & 1  & 0  & 0  \\\\\n    0  & 0  & 1  & 0  \\\\\n    0  & 0  & 0  & 1\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    y_{\\text{AX},t} \\\\\n    y_{\\text{AY},t} \\\\\n    y_{\\text{BX},t} \\\\\n    y_{\\text{BY},t}\n  \\end{bmatrix}\n\\] cuya ecuación queda definida por:\n\\[\n\\begin{align}\n  \\tag{2.2.4}\n  \\boldsymbol{y}_t=\\boldsymbol{S}\\boldsymbol{b}_{t},\n\\end{align}\n\\]\ndonde:\n\n\\(\\boldsymbol{y}_t\\): vector \\(n\\)-dimensional con todas las observaciones de la jerarquía en el tiempo \\(t\\)\n\\(\\boldsymbol{S}\\): matriz de acumulación\n\\(\\boldsymbol{b}_t\\): es un vector \\(m\\)-dimensional de las observaciones en el nivel último inferior de la jerarquía.\n\n¿Qué representa nuestra matriz, cómo induce las relaciones de jerarquía, cómo se construye?\n\nLa primer fila de la matriz representa la ecuación (2.2.1), la serie en el nivel más alto de la jerarquía\nEn este caso, la segunda y tercer fila representan la ecuación (2.2.2) correspondientes a las series \\(A\\) y \\(B\\) para el nivel 2 de nuestro ejemplo.\nEn este caso, cuarta y quinta fila representan la ecuación (2.2.3) correspondientes a las series \\(X\\) y \\(Y\\) para el nivel 2 de nuestro ejemplo.\n\\(\\vdots\\) (similar al nivel 2, se construyen niveles adicionales inferiores hasta llegar al penúltimo nivel)\n\n\nEl último nivel deberá ser presentado por una matriz identidad \\(I_m\\).\n\n\n\n\n\n\n\nTip\n\n\n\nLas series de tiempo agrupadas pueden interpretarse como series jerárquicas sin la restricción de una estructura única, esto es el órden de agrupación no es único\n\n\nEjemplo. Kaggle Tabular Playground Series - Sep 2022. Enfoque Serie de Tiempo Agrupadas\nEn la sección 2.1 sobre series de tiempo jerárquicas, describimos previamente los objetivos del área comercial e identificamos uno particularmente interesante que corresponde a series de tiempo agrupadas, el conocer los niveles de venta por país, tienda y producto para garantizar un invenatario óptimo.\nPara crear series de tiempo agrupadas utilizando la paquetería fpp3, también utilizamos la funcion aggregate_key() para definir atributos o grupos de interés cruzados bajo la sintaxis attributo1*atributo2.\n\nsales_m |>\n  aggregate_key( country*store*product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(!is_aggregated(country), !is_aggregated(store), !is_aggregated(product)) |>\n  autoplot(num_sold) +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales: por país, tienda y producto\") +\n  facet_wrap(vars(country), scales = \"free_y\", ncol = 2) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nsales_m |>\n  aggregate_key( country*store*product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(!is_aggregated(country), !is_aggregated(store), !is_aggregated(product)) |>\n  mutate(store = as.character(store),product = as.character(product)) |>\n  ggplot(aes(x = date, y = num_sold, group = store, colour = store)) +\n  stat_summary(fun = sum, geom = \"line\") +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales: por país, tienda y producto\") +\n  facet_wrap(~as.character(country), scales = \"free_y\", ncol = 2) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\nsales_m |>\n  aggregate_key( country*store*product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(!is_aggregated(country), !is_aggregated(store), !is_aggregated(product)) |>\n  mutate(store = as.character(store),product = as.character(product)) |>\n  ggplot(aes(x = date, y = num_sold, group = product, colour = product)) +\n  stat_summary(fun = sum, geom = \"line\") +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales: por país, tienda y producto\") +\n  facet_wrap(~as.character(country), scales = \"free_y\", ncol = 2) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "02-proyecto.html#estructura-mixta-jerárquica-y-agrupada",
    "href": "02-proyecto.html#estructura-mixta-jerárquica-y-agrupada",
    "title": "2  Tipos de estructuras que surgen en datos desagregados",
    "section": "2.3 Estructura Mixta Jerárquica y Agrupada",
    "text": "2.3 Estructura Mixta Jerárquica y Agrupada\nAhora bien, es posible que en algunos casos los factores de desagregación estén tanto anidados como cruzados (intersectados) al mismo tiempo, por lo que nuestra estructura es mixta, jerárquica y agrupada al mismo tiempo.\nContinuemos con nuestro caso de estudio de los datos de Ventas de productos en países europeos (Kaggle), los datos pueden desagregarse en los 4 productos sin necesidad de anidarse en cualquiera de las otras variables, país o tienda, esto es, podemos analizar nuestros datos o hacer predicciones por producto para toda la región europea con presencia comercial, pero también es posible realizar esto por cada país y por cada tienda. Se define esta estructura como anidación de geografía jerárquica cruzada o “intersectada” con el producto.\nContinuando con el uso del paquete de los autores fpp3, lo anterior se implementa combinando factores utilizando la función aggregate_key().\n\nsales_m |>\n  aggregate_key((country / store) * product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(is_aggregated(country), is_aggregated(store), !is_aggregated(product)) |>\n  autoplot(num_sold) +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales por producto\") +\n  facet_wrap(vars(product), scales = \"free_y\", ncol = 2) +\n  theme(legend.position = \"none\")\n\n\n\n\n\nsales_m |>\n  aggregate_key((country/store)*product, num_sold = sum(num_sold,na.rm=TRUE)/1000) |>\n  filter(!is_aggregated(country), !is_aggregated(store), !is_aggregated(product)) |>\n  mutate(store = as.character(store),product = as.character(product)) |>\n  ggplot(aes(x = date, y = num_sold, group = product, colour = product)) +\n  stat_summary(fun = sum, geom = \"line\") +\n  labs(x = \"Mes/Año\" , y = \"Ventas (miles)\",title = \"Ventas totales: por país y producto\") +\n  facet_wrap(~as.character(country), scales = \"free_y\", ncol = 2) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "03-proyecto.html#enfoque-ascendente-bottom-up",
    "href": "03-proyecto.html#enfoque-ascendente-bottom-up",
    "title": "3  Enfoque tradicional de predicciones a un nivel de agregación",
    "section": "3.1 Enfoque ascendente (bottom-up)",
    "text": "3.1 Enfoque ascendente (bottom-up)\n\nGeneramos las predicciones para cada serie en el último nivel inferior (fondo - bottom)\nAdicionamos para generar las predicciones de todas las series en la estructura.\n\nConsideremos nuevamente Figura A: diagrama para series de tiempo jerárquicas, generamos predicciones para \\(h\\) periodos adelante para cada una de las series en el último nivel inferior, esto es \\(\\hat{y}_{T+h|T}\\):\n\\[\n\\begin{align}\n\\tag{3.1.1}\n\\hat{y}_{\\text{AA},h}, \\quad \\hat{y}_{\\text{AB},h}, \\quad\\hat{y}_{\\text{AC},h}, \\quad\\hat{y}_{\\text{BA},h},   \\quad \\text{y} \\quad \\hat{y}_{\\text{BB},h}, \\quad\n\\end{align}\n\\] Adicionando, obtenemos predicciones coherentes para \\(h\\) periodos adelante para el resto de las series:\n\\[\n\\begin{align}\n\\tag{3.1.2}\n\\tilde{y}_{h} = \\hat{y}_{\\text{AA},h} + \\hat{y}_{\\text{AB},h} + \\hat{y}_{\\text{AC},h} +\n\\hat{y}_{\\text{BA},h}  \\\\\n\\tilde{y}_{\\text{A},h} = \\hat{y}_{\\text{AA},h} + \\hat{y}_{\\text{AB},h} +\n\\hat{y}_{\\text{AC},h}, \\\\\n\\text{y} \\quad\n\\tilde{y}_{\\text{B},h}=\\hat{y}_{\\text{BA},h}+\\hat{y}_{\\text{BB},h}\n\\end{align}\n\\]\n\n\n\n\n\n\nNota\n\n\n\nSe utiliza la notación tilde “~” para indicar predicción coherente.\n\n\nImplementación fpp3.\n- función bu = bottom_up() dentro de la función reconcile().\n\n\n\n\n\n\nNota\n\n\n\n\nVentaja:las predicciones se realizan en el último nivel inferior lo que implica que no exista pérdida de información debida a la agragación.\nDesventaja: este nivel puede ser altamente ruidoso y dificultar el modelado y predicciones. Pensemos por ejemplo en los modelos de COVID donde la información de algunos países es altamente ruidosa debido al tamaño bajo de sus poblaciones que implica muestras bajas y mayor variabilidad en el agregado."
  },
  {
    "objectID": "03-proyecto.html#enfoque-descendente-top-down",
    "href": "03-proyecto.html#enfoque-descendente-top-down",
    "title": "3  Enfoque tradicional de predicciones a un nivel de agregación",
    "section": "3.2 Enfoque descendente (top-down)",
    "text": "3.2 Enfoque descendente (top-down)\n\nGeneramos las predicciones para el Total de las series \\(y_t\\)\nDesagregamos hacia abajo siguiendo la secuencia jerárquica.\n\nDenotemos por \\(p_1,\\dots, p_m\\) un conjunto de proporciones de desagregación que determinan la forma en que debe distribuirse la serie Total para generar las predicciones de los niveles inferiores.\nSi utilizamos proporciones en el ejemplo Figura A: diagrama para series de tiempo jerárquicas, obtenemos:\n\\[\n\\begin{align}\n\\tag{3.2.1}\n\\tilde{y}_{\\text{AA},t}=p_1\\hat{y}_t, \\quad \\tilde{y}_{\\text{AB},t}=p_2\\hat{y}_t, \\quad\n\\tilde{y}_{\\text{AC},t}=p_3\\hat{y}_t,  \\\\\n\\quad \\tilde{y}_{\\text{BA},t}=p_4\\hat{y}_t, \\quad \\tilde{y}_{\\text{BB},t}=p_5\\hat{y}_t.\n\\end{align}\n\\] Habiendo obtenido las predicciones para \\(h\\) periodos adelante de la serie última inferior, éstas se agregan para generar las predicciones coherentes para el resto de la series.\nImplementación fpp3:\n- función bu = top_down() dentro de la función reconcile().\n\nA continuación revisarempos los dos métodos más comunes para especificar las proporciones de desagregación utilizando las proporciones históricas de los datos. _____________\n\n3.2.1 Proporciones históricas promedio (Average historical proportions)\n\\[\n\\begin{align}\n\\tag{3.2.2}\np_j=\\frac{1}{T}\\sum_{t=1}^{T}\\frac{y_{j,t}}{{y_t}} \\quad j=1,\\dots,m\n\\end{align}\n\\]\nCada proporción \\(p_j\\) refleja el promedio de las proporciones históricas de las series en el último nivel inferior \\(y_{j,t}\\) en el periodo \\(t=1,\\dots,T\\) relativo al total agregado en \\(y_t\\).\nImplementación.\n- Utilizando el paquete fpp3, este enfoque se realiza utilizando la función top_down ajustando el parámetro method = average_proportions.\n\n\n3.2.2 Proporciones de los promedios históricos (Proportions of the historical averages)\n\\[\n\\begin{align}\n\\tag{3.2.3}\np_j={\\sum_{t=1}^{T}\\frac{y_{j,t}}{T}}\\Big/{\\sum_{t=1}^{T}\\frac{y_t}{T}} \\quad \\text{para} \\quad j=1,\\dots,m\n\\end{align}\n\\]\nCada proporción \\(p_j\\) captura el valor promedio histórico de la última serie inferior \\(y_{j,t}\\) relativo al valor promedio del total agregado \\(y_t\\).\nImplementación: Utilizando el paquete fpp3, este enfoque se realiza utilizando la función top_down ajustando el parámetro method = proportion_averages\n\n\n\n\n\n\nNota\n\n\n\n\nVentaja:simplicidad… sólo se requiere generar predicciones para la serie más agregada del nivel superior mayor. Estos enfoques producen predicciones confiables para niveles agregados o con pocos datos.\nDesventaja: pérdida de información debida a la agregación; no es posible explotar las características de las series individuales, tales como estacionalidad, tendencia, días de asueto, etc.\n\n\n\n\n\n3.2.3 Forecast proportions\nEn los métdos “top-down”, al calcular las proporciones de desagreagación con información histórica, no se capturan cambios en el tiempo, perdemos precisión en las predicciones frente al método “bottom-up” en niveles inferiores de la jerarquía.\n¿Cómo lo resolvemos?\nProporciones basadas en las predicciones…\nMetodología.\nJerarquía de \\(k=1\\) nivel.\n\nPredicciones iniciales: se generan a \\(h\\) periodos adelante para todas las series (no son coherentes ni utilizables).\nProporciones de Predicción: calculamos las proporciones para cada predicción inicial en el nivel último inferior agregando para todas las predicciones iniciales en este nivel.\nCon estas proporciones desagregamos el nivel superior de la predicción inicial para generar predicciones coherentes para toda la jerarquía.\n\nPara una jerarquía de \\(k\\)-niveles.\n\nRepite el proceso para cada nodo iniciando con el nivel superior y hacia abajo, dando como resultado una fórmula general para obtener las proporciones de predicción:\n\n\\[\n\\begin{align}\n\\tag{3.2.4}\np_j=\\prod^{K-1}_{\\ell=0}\\frac{\\hat{y}_{j,h}^{(\\ell)}}{\\hat{S}_{j,h}^{(\\ell+1)}}\n\\end{align}\n\\] donde:\n\n\\(j=1,\\dots,m\\).\n\n\\(\\hat{y}_{j,h}^{(\\ell)}\\) es la predicción inicial a \\(h\\) periodos de la serie correspondiente al nodo que está \\(\\ell\\) niveles por encima de \\(j\\).\n\n\\(\\hat{S}_{j,h}^{(\\ell+1)}\\) es la suma de las predicciones iniciales a \\(h\\) periodos por debajo del nodo que está \\(\\ell\\) niveles por encima de \\(j\\) y está direcatmente conectada a ese nodo.\n\nCon estas proporciones desagregamos las predicciones iniciales del “Total” de las series para generar predicciones coherentes a \\(h\\) periodos de las series en el último nivel inferior.\nPara ejemplificar lo anterior, usaremos el ya conocido por nosotros diagrama Figura A de la sección 2.\n\nAsumiremos que se han generado predicciones iniciales para cada serie en la jerarquía.\nRecordemos que en cualquier método “top-down”, para las series en el máximo nivel superior “Total”: \\(\\tilde{y}_{h}=\\hat{y}_{h}\\).\n\n\\[\n\\begin{align}\n\\tag{3.2.5}\n\\hat{y}_{\\text{A},h}^{(1)} = \\hat{y}_{\\text{B},h}^{(1)} = \\hat{y}_{h} =  \\tilde{y}_{h};\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\tag{3.2.6}\n\\hat{y}_{\\text{AA},h}^{(1)} = \\hat{y}_{\\text{AB},h}^{(1)} = \\hat{y}_{\\text{AC},h}^{(1)} =  \\hat{y}_{\\text{A},h};\n\\end{align}\n\\] \\[\n\\begin{align}\n\\tag{3.2.7}\n\\hat{y}_{\\text{AA},h}^{(2)} = \\hat{y}_{\\text{AB},h}^{(2)} = \\hat{y}_{\\text{AC},h}^{(2)} = \\hat{y}_{\\text{BA},h}^{(2)} = \\hat{y}_{\\text{BB},h}^{(2)} = \\hat{y}_{h}=\\tilde{y}_{h};\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\tag{3.2.8}\n\\hat{S}_{\\text{AA},h}^{(1)} = \\hat{S}_{\\text{AB},h}^{(1)} = \\hat{S}_{\\text{AC},h}^{(1)} =  \\hat{y}_{\\text{AA},h}+\\hat{y}_{\\text{AB},h}+\\hat{y}_{\\text{AC},h};\n\\end{align}\n\\]\n\\[\n\\begin{align}\n\\tag{3.2.9}\n\\hat{S}_{\\text{AA},h}^{(2)} = \\hat{S}_{\\text{AB},h}^{(2)} = \\hat{S}_{\\text{AC},h}^{(2)} = \\hat{S}_{\\text{A},h}^{(1)} = \\hat{S}_{\\text{B},h}^{(1)} = \\hat{S}_{h}= \\hat{y}_{\\text{A},h}+\\hat{y}_{\\text{B},h};\n\\end{align}\n\\]\nLas predicciones coherentes están dadas por (partiendo de la rama izquierda más alejada de la jerarquía):\n\\[\n\\begin{align}\n\\tag{3.2.10}\n\\tilde{y}_{\\text{A},h} = \\Bigg(\\frac{\\hat{y}_{\\text{A},h}}{\\hat{S}_{\\text{A},h}^{(1)}}\\Bigg)\\tilde{y}_{h} =\n\\Bigg(\\frac{\\hat{y}_{\\text{AA},h}^{(1)}}{\\hat{S}_{\\text{AA},h}^{(2)}}\\Bigg) \\tilde{y}_{h}\n\\end{align}\n\\] y\n\\[\n\\begin{align}\n\\tag{3.2.11}\n  \\tilde{y}_{\\text{AA},h} = \\Bigg(\\frac{\\hat{y}_{\\text{AA},h}}{\\hat{S}_{\\text{AA},h}^{(1)}}\\Bigg)\n  \\tilde{y}_{\\text{A},h} = \\Bigg(\\frac{\\hat{y}_{\\text{AA},h}}{\\hat{S}_{\\text{AA},h}^{(1)}}\\Bigg)\n  \\Bigg(\\frac{\\hat{y}_{\\text{AA},h}^{(1)}}{\\hat{S}_{AA,h}^{(2)}}\\Bigg)\n  \\tilde{y}_{h}.\n\\end{align}\n\\]\nPor consecuencia:\n\\[\n\\begin{align}\n\\tag{3.2.12}\n  p_1=\\Bigg(\\frac{\\hat{y}_{\\text{AA},h}}{\\hat{S}_{\\text{AA},h}^{(1)}}\\Bigg)\n  \\Bigg(\\frac{\\hat{y}_{\\text{AA},h}^{(1)}}{\\hat{S}_{AA,h}^{(2)}}\\Bigg).\n\\end{align}\n\\] Similarmente para las otras proporciones.\nImplementación:.\n- Utilizando el paquete fpp3, este enfoque se realiza utilizando la función top_down ajustando el parámetro method = forecast_proportions. Este parámetro es la selección por default para la función top_down cuando éste no se especifica.\n\n\n\n\n\n\nNota\n\n\n\n\nDesventaja (para todos los métodos top-down): las predicciones coherentes que se generan no son insesgadas aún cuando la base de predicción sea insesgada."
  },
  {
    "objectID": "03-proyecto.html#enfoque-middle-out",
    "href": "03-proyecto.html#enfoque-middle-out",
    "title": "3  Enfoque tradicional de predicciones a un nivel de agregación",
    "section": "3.3 Enfoque middle-out",
    "text": "3.3 Enfoque middle-out\nEste método combina los enfoques bottom-up y top-down y se utiliza estrictamente para estructuras de agregación jerárquica.\n\nElegir un nivel intermedio para el cual se realizan las predicciones de todas las series en este nivel\nPara las series superiores, se generan predicciones coherentes utilizando el enfoque bottom-up agregando las predicciones del nivel medio hacia “arriba”.\nPara las series inferiores, se generan predicciones coherentes utilizando el enfoque top-down agregando las predicciones del nivel medio hacia “abajo”.\n\nImplementación:\n\nfunción middle_out().\n\nEspecificar el nivel medio con el argumento level.\n\nSeleccionar el enfoque top-down con el argumento method."
  },
  {
    "objectID": "04-proyecto.html#mapeo-con-matrices-mapping-matrices",
    "href": "04-proyecto.html#mapeo-con-matrices-mapping-matrices",
    "title": "4  Reconciliación en las Predicciones",
    "section": "4.1 Mapeo con Matrices (Mapping matrices)",
    "text": "4.1 Mapeo con Matrices (Mapping matrices)\nLa notación matricial facilita la representación de todos los métodos de predicción de series de tiempo jerárquicos o agrupados.\nPredicciones base. - Predecimos todas las series sin considerar restricciones de agregación. - Denotamos \\(\\hat{\\boldsymbol{y}}_h\\) con \\(h\\) horizonte de predicción. - Apiladas en el mismo orden que los datos \\(\\boldsymbol{y}_t\\)\nEl conjunto de todos los métodos de predicción, ya sea para estructuras jerárquicas o agrupadas, puede representarse por (sólo para métodos generales de reconciliación lineal):\n\\[\n\\begin{align}\n\\tag{4.1.3}\n  \\tilde{\\boldsymbol{y}}_h=\\boldsymbol{S}\\boldsymbol{G}\\hat{\\boldsymbol{y}}_h\n\\end{align}\n\\]\ndonde:\n\n\\(\\boldsymbol{G}\\) matriz que mapea las predicciones base al nivel inferior.\n\n\\(\\boldsymbol{S}\\) matriz de acumulación, las anteriores son adicionadas hacia arriba bajo la estructura de agregación para producir el conjunto predicciones coherentes \\(\\boldsymbol{y}_h\\).\n\nLa matriz \\(\\boldsymbol{G}\\) se define con base en el método implementado:\nEjemplo: bajo la jerarquía: Figura A: diagrama para series de tiempo jerárquicas\nMétodo bottom-up\n\\[\n\\boldsymbol{G}=\n  \\begin{bmatrix}\n    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\\\\n    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\\\\n    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\\\\n    0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\\\\n    0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\\\\n  \\end{bmatrix}.\n\\] Notemos que la matriz \\(\\boldsymbol{G}\\) está particionada en 2:\n\nLas columnas de 0’s corresponden a las predicciones base de la series que están por encima del nivel inferior (fondo).\nLa matriz identidad de dimensión \\(m\\) recoge las predicciones base del nivel inferior (fondo), que posteriormente son sumadas por la matris \\(\\boldsymbol{S}\\)\n\n\nMétodo: cualquier top-down\n\\[\n\\boldsymbol{G}=\n    \\begin{bmatrix}\n      p_1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n      p_2 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n      p_3 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n      p_4 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n      p_5 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n    \\end{bmatrix}.\n\\]\n\nLa primer columna corresponde incluye el conjunto de proporciones que distribuyen las predicciones base del máximo nivel superior (top) hacia el nivel inferior (fondo), que posteriormente son adicionadas por la matriz \\(\\boldsymbol{S}\\)\nEl resto de las columnas mapean a 0 las predicciones base que están por debajo del máximo nivel superior de agregación.\n\n\nMétodo: middle-out.\n\nLa matriz \\(\\boldsymbol{G}\\) es una comnbinación de las dos anteriores.\nUtilizando un cojunto de proporciones, las predicciones base para algún nivel preseleccionado será desagregado hacia el nivel inferior, el resto de las predicciones se mapean a 0.\nFinalmente, las predicciones inferiores (fondo) son sumadas ascendiendo a través de la jerarquía via la matriz de agregación."
  },
  {
    "objectID": "04-proyecto.html#reconciliación-de-las-predicciones",
    "href": "04-proyecto.html#reconciliación-de-las-predicciones",
    "title": "4  Reconciliación en las Predicciones",
    "section": "4.2 Reconciliación de las Predicciones",
    "text": "4.2 Reconciliación de las Predicciones\nLos métodos estuadiados (tradicionales) tienen como limitante el hecho de enfocarse en una predicción base desde un solo nivel de agregación para porteriormente agregar o desagregar y generar predicciones coherentes para el resto el resto de las series.\nSabemos que producto de matrices \\(\\boldsymbol{SG}\\) combina y reconcilia todas las predicciones base dando lugar a predicciones coherentes…\n**¿Podemos encontrar la matriz óptima \\(\\boldsymbol{G}\\) para obtener la mayor perecisión?"
  },
  {
    "objectID": "04-proyecto.html#enfoque-de-reconciliación-óptima-mint",
    "href": "04-proyecto.html#enfoque-de-reconciliación-óptima-mint",
    "title": "4  Reconciliación en las Predicciones",
    "section": "4.3 Enfoque de Reconciliación Óptima MinT",
    "text": "4.3 Enfoque de Reconciliación Óptima MinT\nSin profundizar mucho en este tema, sólo mencionaremos el objetivo, que consiste en buscar la matriz \\(G\\) que minimice la varianza de la predicción Total para el conjunto de predicciones coherentes, por lo que se le denomina\nMétodo de Reconciliación Óptima por Traza Mínima, Minimum Trace (Mint)"
  },
  {
    "objectID": "05-proyecto.html#serie-de-tiempo-total",
    "href": "05-proyecto.html#serie-de-tiempo-total",
    "title": "5  Predicciones para resolver el Problema de Ventas",
    "section": "5.1 Serie de tiempo total",
    "text": "5.1 Serie de tiempo total\nPrimero, supongamos que queremos pronosticar las ventas totales en toda la zona de Europa utilizando información de 2017 a 2020 a nivel mensual, y queremos realizar predicciones dos años hacia adelante, es decir, 24 periodos adicionales. Para ello, utilizaremos un modelo de espacio de estados con nivel local con tendencia y estacionalidad con 12 periodos (meses).\nA continuación se muestra el ajuste con el modelo a través de bsts.\n\najuste <- TS[[\"total\"]]\nplot(ajuste, \"state\", burn = 2000)\n\n\n\n\nEn la siguiente figura podemos ver la desagregación de la serie temporal en tendencia y estacionalidad. Podemos ver que la tendencia tiene un comportamiento como el descrito en la Sección 2 (Análisis de la tendencia) ya que con la pandemia se tuvo una caída abrupta en las ventas para todos los países durante el primer trimestre de 2020 y una tendencia de recuperación en el nivel de ventas posterior a ese trimestre. Para la estacionalidad también podemos ver un comportamiento similar y bien marcado como el de la Sección 2 (Análisis de estacionalidad).\n\ndims <- ajuste$state.contributions |> dim()\ntiempo <- dims[3]\ncontribuciones_tbl <- map(1:tiempo, ~ ajuste$state.contributions[,,.x] |> \n  as_tibble() |> mutate(t = .x)) |> bind_rows() |> \n  pivot_longer(trend:seasonal.12.1, values_to = \"value\", names_to = \"comp\") |> \n  group_by(t, comp) |> \n  summarise(media = mean(value), q5 = quantile(value, 0.05),\n            q95 = quantile(value, 0.95), .groups = \"drop\")\n\nggplot(contribuciones_tbl, \n  aes(x = t, y = media, ymin = q5, ymax = q95)) +\n  geom_ribbon(alpha = 0.1) + \n  geom_line(alpha = 1) + facet_wrap(~ comp, scales = \"free_y\", ncol = 1)\n\n\n\n\nPodemos notar que no existe correlación al menos a un paso. Sin embargo, gracias al gráfico “Q-Q” podemos notar que existen errores grandes en algunos meses que no pudieron ser captados por la propuesta de modelo.\n\npred_errors_tbl <- \n  ajuste$one.step.prediction.errors |> \n  t() |> as_tibble() |>\n  mutate(t = 1: tiempo) |> \n  pivot_longer(-c(t), names_to = \"sim\", values_to = \"valor\") |> \n  group_by(t) |> \n  summarise(valor = mean(valor)) |> \n  as_tsibble(index = t)\n\nACF(pred_errors_tbl) |> \n  autoplot() + ylim(c(-1,1))\n\n\n\n\n\nerror <- ajuste$one.step.prediction.errors |> apply(2, mean)\nqqnorm(error)\nqqline(error)\n\n\n\n\nFinalmente, mostramos los pronósticos hechos a 24 meses hacia adelante, donde podemos ver que a mayor tiempo, el intervalo de confianza del pronóstico se amplía debido al aumento de la varianza.\n\npred <- predict(ajuste, horizon = 24,burn=2000)\nplot(pred)"
  },
  {
    "objectID": "05-proyecto.html#problema-en-series-jerárquicas",
    "href": "05-proyecto.html#problema-en-series-jerárquicas",
    "title": "5  Predicciones para resolver el Problema de Ventas",
    "section": "5.2 Problema en series jerárquicas",
    "text": "5.2 Problema en series jerárquicas\nUna vez con los pronósticos de la serie total de toda Europa, el negocio necesita saber el pronóstico para cada país, para cada tipo de tienda dentro de cada país, y para cada producto de cada tienda de cada país, con el fin de tomar acciones en casos de que alguna unidad de negocio tenga problemas con sus niveles de ventas. Para ello, se realizan ajustes con el mismo modelo de espacio de estados con nivel local con tendencia y estacionalidad con 12 periodos, aunque para todos los niveles de cada unidad de negocio.\nAquí es donde se presenta el principal problema de este tipo de series de tiempo, ya que la suma de todas las series por producto, tienda o país debería ser la misma que la serie total en toda Europa, lo cual no siempre pasa y llega a provocar dudas sobre cuál serie es la correcta y debería seguirse.\nLo anterior se ilustra en el siguiente gráfico que compara la serie total contra la suman de todas las series a nivel producto, tienda y país. La discrepancia se nota más cuando se realizan pronósticos en ventanas de tiempo no observadas (parte derecha a partir de la línea vertical punteada).\n\n\n\n\n\n\nNota\n\n\n\nLas 3 series presentadas sólo intentan ilustrar el problema de discrepancia, sin embargo, existen otras combinaciones en la jerarquía que tienen el mismo problema, por ejemplo, sumar todas las series de un producto de un país determinado contra la serie de ese mismo país.\n\n\n\n\nCódigo\najuste <- TS[[\"total\"]]\ndims <- ajuste$state.contributions |> dim()\ntiempo <- dims[3]\ncontribuciones_total <- map(1:tiempo, ~ ajuste$state.contributions[,,.x] |> \n  as_tibble() |> mutate(t = .x)) |> bind_rows() |> \n  pivot_longer(trend:seasonal.12.1, values_to = \"value\", names_to = \"comp\") |> \n  group_by(t, comp) |> \n  summarise(media = mean(value), q5 = quantile(value, 0.05),\n            q95 = quantile(value, 0.95), .groups = \"drop\") |>\n  group_by(t) |>\n  summarise(media_total = sum(media))\npred <- predict(ajuste, horizon = 24,burn=2000)$mean\ncontribuciones_total<-rbind(contribuciones_total,tibble(t = 49:72, media_total = pred))\n\n\ni<-0\nfor(c in unique(sales_m$country)){\n  for(s in unique(sales$store)){\n    for(p in unique(sales$product)){\n      ajuste <- TS[[paste(c,s,p,sep = \"_\")]]\n      dims <- ajuste$state.contributions |> dim()\n      tiempo <- dims[3]\n      contribuciones_tbl <- map(1:tiempo, ~ ajuste$state.contributions[,,.x] |> \n        as_tibble() |> mutate(t = .x)) |> bind_rows() |> \n        pivot_longer(trend:seasonal.12.1, values_to = \"value\", names_to = \"comp\") |> \n        group_by(t, comp) |> \n        summarise(media = mean(value), q5 = quantile(value, 0.05),\n                  q95 = quantile(value, 0.95), .groups = \"drop\") |>\n        group_by(t) |>\n        summarise(media_producto = sum(media)) |>\n        mutate(p = paste(c,s,p,sep = \"_\"))\n        pred <- predict(ajuste, horizon = 24,burn=2000)$mean\n        contribuciones_tbl<-rbind(contribuciones_tbl,tibble(t = 49:72, media_producto = pred,p = paste(c,s,p,sep = \"_\")))\n        if(i==0){contribuciones_producto<-contribuciones_tbl}else{contribuciones_producto<-rbind(contribuciones_producto,contribuciones_tbl)}\n        i<-i+1\n    }\n  }\n}\ncontribuciones_producto_tbl<-contribuciones_producto\ncontribuciones_producto<-contribuciones_producto |>\n  group_by(t) |>\n  summarise(media_producto = sum(media_producto)) \n\n\ni<-0\nfor(c in unique(sales_m$country)){\n  for(s in unique(sales$store)){\n    ajuste <- TS[[paste(c,s,sep = \"_\")]]\n    dims <- ajuste$state.contributions |> dim()\n    tiempo <- dims[3]\n    contribuciones_tbl <- map(1:tiempo, ~ ajuste$state.contributions[,,.x] |> \n      as_tibble() |> mutate(t = .x)) |> bind_rows() |> \n      pivot_longer(trend:seasonal.12.1, values_to = \"value\", names_to = \"comp\") |> \n      group_by(t, comp) |> \n      summarise(media = mean(value), q5 = quantile(value, 0.05),\n                q95 = quantile(value, 0.95), .groups = \"drop\") |>\n      group_by(t) |>\n      summarise(media_store = sum(media)) |>\n      mutate(p = paste(c,s,sep = \"_\"))\n      pred <- predict(ajuste, horizon = 24,burn=2000)$mean\n      contribuciones_tbl<-rbind(contribuciones_tbl,tibble(t = 49:72, media_store = pred,p = paste(c,s,sep = \"_\")))\n      if(i==0){contribuciones_store<-contribuciones_tbl}else{contribuciones_store<-rbind(contribuciones_store,contribuciones_tbl)}\n      i<-i+1\n  }\n}\ncontribuciones_store_tbl<-contribuciones_store\ncontribuciones_store<-contribuciones_store |>\n  group_by(t) |>\n  summarise(media_store = sum(media_store)) \n\n\ni<-0\nfor(c in unique(sales_m$country)){\n  ajuste <- TS[[paste(c,sep = \"_\")]]\n  dims <- ajuste$state.contributions |> dim()\n  tiempo <- dims[3]\n  contribuciones_tbl <- map(1:tiempo, ~ ajuste$state.contributions[,,.x] |> \n    as_tibble() |> mutate(t = .x)) |> bind_rows() |> \n    pivot_longer(trend:seasonal.12.1, values_to = \"value\", names_to = \"comp\") |> \n    group_by(t, comp) |> \n    summarise(media = mean(value), q5 = quantile(value, 0.05),\n              q95 = quantile(value, 0.95), .groups = \"drop\") |>\n    group_by(t) |>\n    summarise(media_country = sum(media)) |>\n    mutate(p = paste(c,sep = \"_\"))\n    pred <- predict(ajuste, horizon = 24,burn=2000)$mean\n    contribuciones_tbl<-rbind(contribuciones_tbl,tibble(t = 49:72, media_country = pred,p = paste(c,sep = \"_\")))\n    if(i==0){contribuciones_country<-contribuciones_tbl}else{contribuciones_country<-rbind(contribuciones_country,contribuciones_tbl)}\n    i<-i+1\n}\ncontribuciones_country_tbl <- contribuciones_country\ncontribuciones_country<-contribuciones_country |>\n  group_by(t) |>\n  summarise(media_country = sum(media_country)) \n\n\ncontribuciones_tbl<-cbind(\n  contribuciones_total,\n  contribuciones_producto|>select(media_producto),\n  contribuciones_store |>select(media_store),\n  contribuciones_country |>select(media_country)\n) |>\n  mutate(\n    diff_total_producto = media_total - media_producto,\n    diff_total_store = media_total - media_store,\n    diff_total_country = media_total - media_country\n  )\n\ncontribuciones_tbl_2<-contribuciones_producto_tbl |>\n  separate(p, c(\"country\",\"store\",\"product\"),sep=\"_\") |>\n  group_by(t,country) |>\n  summarise(media_producto = sum(media_producto)) |>\n  ungroup()\ncontribuciones_tbl_2 <- merge(contribuciones_tbl_2,contribuciones_country_tbl, by.x = c(\"t\",\"country\"),by.y =c(\"t\", \"p\"),all=TRUE) \n\ncontribuciones_tbl_3<-contribuciones_store_tbl |>\n  separate(p, c(\"country\",\"store\"),sep=\"_\") |>\n  group_by(t,country) |>\n  summarise(media_store = sum(media_store)) |>\n  ungroup()\ncontribuciones_tbl_3 <- merge(contribuciones_tbl_3,contribuciones_country_tbl, by.x = c(\"t\",\"country\"),by.y =c(\"t\", \"p\"),all=TRUE) \n\ni<-0\nfor(c in unique(sales_m$country)){\n  for(s in unique(sales$store)){\n    for(p in unique(sales$product)){\n      ajuste <- TSp[[paste(c,s,p,sep = \"_\")]]\n      dims <- ajuste$state.contributions |> dim()\n      tiempo <- dims[3]\n      contribuciones_p <- map(1:tiempo, ~ ajuste$state.contributions[,,.x] |> \n        as_tibble() |> mutate(t = .x)) |> bind_rows() |> \n        pivot_longer(trend:seasonal.12.1, values_to = \"value\", names_to = \"comp\") |> \n        group_by(t, comp) |> \n        summarise(media = mean(value), q5 = quantile(value, 0.05),\n                  q95 = quantile(value, 0.95), .groups = \"drop\") |>\n        group_by(t) |>\n        summarise(media_producto = sum(media)) |>\n        mutate(p = paste(c,s,p,sep = \"_\"))\n        pred <- predict(ajuste, horizon = 24,burn=2000)$mean\n        contribuciones_p<-rbind(contribuciones_p,tibble(t = 49:72, media_producto = pred,p = paste(c,s,p,sep = \"_\")))\n        if(i==0){contribuciones_p_producto<-contribuciones_p}else{contribuciones_p_producto<-rbind(contribuciones_p_producto,contribuciones_p)}\n        i<-i+1\n    }\n  }\n}\n\npp1<-contribuciones_producto_tbl |>\n  separate(p, c(\"country\",\"store\",\"product\"),sep=\"_\") |>\n  filter(country == \"Poland\") |>\n  filter(store == \"KaggleMart\") \n\npp2<-contribuciones_store_tbl |>\n  separate(p, c(\"country\",\"store\"),sep=\"_\") |>\n  filter(country == \"Poland\") |>\n  filter(store == \"KaggleMart\") \n\npp3<-contribuciones_p_producto |>\n  separate(p, c(\"country\",\"store\",\"product\"),sep=\"_\") |>\n  filter(country == \"Poland\") |>\n  filter(store == \"KaggleMart\") |>\n  group_by(t,country,store) |>\n  mutate(p_all = sum(media_producto)) |>\n  mutate(media_producto = media_producto/p_all)\n\npp4<-merge(pp2,pp3, by =  c(\"t\",\"country\",\"store\"),all=TRUE) |> \n  tibble() |>\n  mutate(media_producto=round(media_producto*media_store,0))\n\npp4<-merge(pp4,pp1, by =  c(\"t\",\"country\",\"store\",\"product\"),all=TRUE,suffixes = c(\"_proportion\",\"_serie\")) |> \n  tibble() \n\nppp1<-contribuciones_producto_tbl |>\n  separate(p, c(\"country\",\"store\",\"product\"),sep=\"_\") |>\n  filter(country == \"Germany\") |>\n  filter(store == \"KaggleRama\") \n\nppp2<-contribuciones_store_tbl |>\n  separate(p, c(\"country\",\"store\"),sep=\"_\") |>\n  filter(country == \"Germany\") |>\n  filter(store == \"KaggleRama\") \n\nppp3<-contribuciones_p_producto |>\n  separate(p, c(\"country\",\"store\",\"product\"),sep=\"_\") |>\n  filter(country == \"Germany\") |>\n  filter(store == \"KaggleRama\") |>\n  group_by(t,country,store) |>\n  mutate(p_all = sum(media_producto)) |>\n  mutate(media_producto = media_producto/p_all)\n\nppp4<-merge(ppp2,ppp3, by =  c(\"t\",\"country\",\"store\"),all=TRUE) |> \n  tibble() |>\n  mutate(media_producto=round(media_producto*media_store,0))\n\nppp4<-merge(ppp4,ppp1, by =  c(\"t\",\"country\",\"store\",\"product\"),all=TRUE,suffixes = c(\"_proportion\",\"_serie\")) |> \n  tibble() \n\n\n\nggplot(contribuciones_tbl)+ \n  geom_line(aes(x = t, y = diff_total_producto/1000,colour = \"Total - Producto\")) +\n  geom_line(aes(x = t, y = diff_total_store/1000,colour = \"Total - Store\")) +\n  geom_line(aes(x = t, y = diff_total_country/1000,colour = \"Total - Country\")) +\n  labs(x = \"t\", y = \"sales (miles)\") +\n  scale_color_manual(name = \"Diferencias\", values = c(\n    \"Total - Producto\" = \"darkblue\",\"Total - Store\" = \"#218611\",\"Total - Country\" =\"#77091b\")) +\n  geom_hline(yintercept = 0, linetype=\"dotted\", color = \"black\", size=1.5) +\n  geom_vline(xintercept = 48, linetype=\"dotted\", color = \"black\", size=1.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "05-proyecto.html#enfoque-ascendente-bottom-up",
    "href": "05-proyecto.html#enfoque-ascendente-bottom-up",
    "title": "5  Predicciones para resolver el Problema de Ventas",
    "section": "5.3 Enfoque ascendente (bottom-up)",
    "text": "5.3 Enfoque ascendente (bottom-up)\nUtilizando este enfoque se ajustan todas las series de tiempo del nivel más bajo, en este caso de los productos de todas las tiendas de todos los países, lo que implica que para este enfoque se tienen que ajustar 48 series de tiempo y posteriormente sumarlas para obtener los pronósticos de cualquiera de los niveles hacia arriba.\n\nggplot(contribuciones_tbl)+ \n  geom_line(aes(x = t, y = media_total/1000,colour = \"Total\") ) +\n  geom_line(aes(x = t, y = media_producto/1000, colour = \"Producto\"),linetype = \"dashed\",size = 1) +\n  labs(x = \"t\", y = \"sales (miles)\") +\n  scale_color_manual(name = \"Serie Jerárquica\", values = c(\"Total\" = \"red\", \"Producto\" = \"darkblue\")) + \n  geom_vline(xintercept = 48, linetype=\"dotted\", color = \"black\", size=1.5)\n\n\n\n\n\nggplot(contribuciones_tbl_2)+ \n  geom_line(aes(x = t, y = media_country/1000,colour = \"Country\") ) +\n  geom_line(aes(x = t, y = media_producto/1000, colour = \"Producto\"),linetype = \"dashed\",size = 1) +\n  labs(x = \"t\", y = \"sales (miles)\") +\n  scale_color_manual(name = \"Serie Jerárquica\", values = c(\"Country\" = \"red\", \"Producto\" = \"darkblue\")) + \n  geom_vline(xintercept = 48, linetype=\"dotted\", color = \"black\", size=1.5) +\n  facet_wrap(vars(country), nrow = 3, scales = \"free_y\")"
  },
  {
    "objectID": "05-proyecto.html#enfoque-middle-out",
    "href": "05-proyecto.html#enfoque-middle-out",
    "title": "5  Predicciones para resolver el Problema de Ventas",
    "section": "5.4 Enfoque middle-out",
    "text": "5.4 Enfoque middle-out\nEl problema con el enfoque anterior es que el nivel más bajo de la serie jerárquica podría ser altamente ruidoso y no todos los nodos podrían tener la suficiente información disponible para hacer un ajuste o predicción, además de que al ser el nivel más bajo el número de series a ajustar podría ser muy amplio. Por lo tanto, utilizaremos un enfoque que combina bottom-up y top-down usando un nivel de la serie de tiempo lo suficientemente robusto como para obtener pronósticos adeacuados además de ajustar una menor cantidad de series de tiempo.\nUtilizaremos el nivel de store para ajustar sólo 12 series de tiempo. Para los niveles hacia arriba usaremos el enfoque bottom-up, es decir, para país y total; mientras que para los niveles hacia abajo usaremos el enfoque top-down con forecast de proporciones, es decir, para producto.\n\nggplot(contribuciones_tbl)+ \n  geom_line(aes(x = t, y = media_total/1000,colour = \"Total\") ) +\n  geom_line(aes(x = t, y = media_store/1000, colour = \"Store\"),linetype = \"dashed\",size = 1) +\n  labs(x = \"t\", y = \"sales (miles)\") +\n  scale_color_manual(name = \"Serie Jerárquica\", values = c(\"Total\" = \"red\", \"Store\" = \"darkblue\")) + \n  geom_vline(xintercept = 48, linetype=\"dotted\", color = \"black\", size=1.5)\n\n\n\n\n\nggplot(contribuciones_tbl_3)+ \n  geom_line(aes(x = t, y = media_country/1000,colour = \"Country\") ) +\n  geom_line(aes(x = t, y = media_store/1000, colour = \"Store\"),linetype = \"dashed\",size = 1) +\n  labs(x = \"t\", y = \"sales (miles)\") +\n  scale_color_manual(name = \"Serie Jerárquica\", values = c(\"Country\" = \"red\", \"Store\" = \"darkblue\")) + \n  geom_vline(xintercept = 48, linetype=\"dotted\", color = \"black\", size=1.5) +\n  facet_wrap(vars(country), nrow = 3, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nPara los pronósticos de las proporciones de cada producto por tienda por país, se normalizó con el fin de que sumen 1, además de que se redondeó el pronóstico, ya que las ventas son valores enteros.\n\n\n\nggplot(pp4)+ \n  geom_line(aes(x = t, y = media_producto_serie/1000,colour = \"Producto\") ) +\n  geom_line(aes(x = t, y = media_producto_proportion/1000, colour = \"Store\"),linetype = \"dashed\",size = 1) +\n  labs(x = \"t\", y = \"sales (miles)\", title = \"Poland & KaggleMart\") +\n  scale_color_manual(name = \"Serie Jerárquica\", values = c(\"Producto\" = \"red\", \"Store\" = \"darkblue\")) + \n  geom_vline(xintercept = 48, linetype=\"dotted\", color = \"black\", size=1.5) +\n  facet_wrap(vars(product), nrow = 2, scales = \"free_y\")\n\n\n\n\n\nggplot(ppp4)+ \n  geom_line(aes(x = t, y = media_producto_serie/1000,colour = \"Producto\") ) +\n  geom_line(aes(x = t, y = media_producto_proportion/1000, colour = \"Store\"),linetype = \"dashed\",size = 1) +\n  labs(x = \"t\", y = \"sales (miles)\", title = \"Germany & KaggleRama\") +\n  scale_color_manual(name = \"Serie Jerárquica\", values = c(\"Producto\" = \"red\", \"Store\" = \"darkblue\")) + \n  geom_vline(xintercept = 48, linetype=\"dotted\", color = \"black\", size=1.5) +\n  facet_wrap(vars(product), nrow = 2, scales = \"free_y\")"
  }
]